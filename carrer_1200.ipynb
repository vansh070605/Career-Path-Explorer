{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5423529f",
   "metadata": {},
   "source": [
    "# Step 1: Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0a9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cdad27",
   "metadata": {},
   "source": [
    "# Step 2: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfe2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quiz/career_quiz_dataset_1200.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c500210",
   "metadata": {},
   "source": [
    "# Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fcee619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StudentID     Q1_Favorite_Subjects         Q2_Enjoyed_Activities  \\\n",
      "0    S00001   Economics, Accountancy             Debating, Reading   \n",
      "1    S00002  Computer Science, Maths         Experiments, Research   \n",
      "2    S00003  Maths, Computer Science       Public Speaking, Coding   \n",
      "3    S00004       Chemistry, Physics               Drawing, Sports   \n",
      "4    S00005       Physics, Chemistry  Experiments, Solving Puzzles   \n",
      "\n",
      "             Q3_Strongest_Skills Q4_Work_Style Q5_Workplace_Preference  \\\n",
      "0      Communication, Creativity          Both                 Startup   \n",
      "1       Design Thinking, Writing     Practical            Research Lab   \n",
      "2  Problem Solving, Presentation   Theoretical                 Startup   \n",
      "3            Leadership, Writing     Practical                Outdoors   \n",
      "4             Research, Teamwork   Theoretical                Outdoors   \n",
      "\n",
      "  Q6_Exam_Readiness Q7_Location_Preference      Q8_Career_Values  \\\n",
      "0             Maybe                 Abroad          Job Security   \n",
      "1             Maybe                 Abroad  Creativity & Freedom   \n",
      "2                No                  India              Balanced   \n",
      "3               Yes                 Abroad  Creativity & Freedom   \n",
      "4             Maybe                 Abroad          Job Security   \n",
      "\n",
      "  Q9_LongTerm_Goal Q10_Academic_Background Recommended_Course  \\\n",
      "0           Doctor             Science-64%              B.Com   \n",
      "1          Teacher             Science-98%  B.Tech Mechanical   \n",
      "2          Teacher                Arts-79%         B.Tech CSE   \n",
      "3    Civil Servant            Commerce-68%         B.Tech ECE   \n",
      "4           Artist                Arts-91%  B.Tech Mechanical   \n",
      "\n",
      "          Recommended_Career Recommended_College_Type  Recommendation_Score  \n",
      "0                 Accountant                   Tier-2                  0.79  \n",
      "1        Mechanical Engineer                   Tier-2                  0.95  \n",
      "2          Software Engineer                   Tier-2                  0.91  \n",
      "3  Embedded Systems Engineer                   Tier-2                  0.78  \n",
      "4        Mechanical Engineer                   Tier-2                  0.94  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3b656",
   "metadata": {},
   "source": [
    "# Step 3: Split features/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f262e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['StudentID', 'Q1_Favorite_Subjects', 'Q2_Enjoyed_Activities',\n",
      "       'Q3_Strongest_Skills', 'Q4_Work_Style', 'Q5_Workplace_Preference',\n",
      "       'Q6_Exam_Readiness', 'Q7_Location_Preference', 'Q8_Career_Values',\n",
      "       'Q9_LongTerm_Goal', 'Q10_Academic_Background', 'Recommended_Course',\n",
      "       'Recommended_Career', 'Recommended_College_Type',\n",
      "       'Recommendation_Score'],\n",
      "      dtype='object')\n",
      "  StudentID     Q1_Favorite_Subjects         Q2_Enjoyed_Activities  \\\n",
      "0    S00001   Economics, Accountancy             Debating, Reading   \n",
      "1    S00002  Computer Science, Maths         Experiments, Research   \n",
      "2    S00003  Maths, Computer Science       Public Speaking, Coding   \n",
      "3    S00004       Chemistry, Physics               Drawing, Sports   \n",
      "4    S00005       Physics, Chemistry  Experiments, Solving Puzzles   \n",
      "\n",
      "             Q3_Strongest_Skills Q4_Work_Style Q5_Workplace_Preference  \\\n",
      "0      Communication, Creativity          Both                 Startup   \n",
      "1       Design Thinking, Writing     Practical            Research Lab   \n",
      "2  Problem Solving, Presentation   Theoretical                 Startup   \n",
      "3            Leadership, Writing     Practical                Outdoors   \n",
      "4             Research, Teamwork   Theoretical                Outdoors   \n",
      "\n",
      "  Q6_Exam_Readiness Q7_Location_Preference      Q8_Career_Values  \\\n",
      "0             Maybe                 Abroad          Job Security   \n",
      "1             Maybe                 Abroad  Creativity & Freedom   \n",
      "2                No                  India              Balanced   \n",
      "3               Yes                 Abroad  Creativity & Freedom   \n",
      "4             Maybe                 Abroad          Job Security   \n",
      "\n",
      "  Q9_LongTerm_Goal Q10_Academic_Background Recommended_Course  \\\n",
      "0           Doctor             Science-64%              B.Com   \n",
      "1          Teacher             Science-98%  B.Tech Mechanical   \n",
      "2          Teacher                Arts-79%         B.Tech CSE   \n",
      "3    Civil Servant            Commerce-68%         B.Tech ECE   \n",
      "4           Artist                Arts-91%  B.Tech Mechanical   \n",
      "\n",
      "          Recommended_Career Recommended_College_Type  Recommendation_Score  \n",
      "0                 Accountant                   Tier-2                  0.79  \n",
      "1        Mechanical Engineer                   Tier-2                  0.95  \n",
      "2          Software Engineer                   Tier-2                  0.91  \n",
      "3  Embedded Systems Engineer                   Tier-2                  0.78  \n",
      "4        Mechanical Engineer                   Tier-2                  0.94  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"quiz/career_quiz_dataset_1200.csv\")\n",
    "\n",
    "print(df.columns)   # show all column names\n",
    "print(df.head())    # preview first rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3e1b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3125\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "               Accountant       0.25      0.12      0.17         8\n",
      "          Artist/Designer       0.09      0.07      0.08        14\n",
      "          Ayurveda Doctor       0.00      0.00      0.00         1\n",
      "         Business Analyst       0.00      0.00      0.00         6\n",
      "           Civil Engineer       0.00      0.00      0.00        12\n",
      "             Counselor/HR       0.25      0.09      0.13        11\n",
      "                  Dentist       0.00      0.00      0.00         1\n",
      "                   Doctor       0.00      0.00      0.00         1\n",
      "        Economist/Analyst       0.25      0.10      0.14        10\n",
      "Embedded Systems Engineer       0.14      0.07      0.10        14\n",
      "        Financial Analyst       0.00      0.00      0.00         6\n",
      "        Homeopathy Doctor       0.00      0.00      0.00         1\n",
      "              IT Engineer       0.00      0.00      0.00        11\n",
      "    IT Support/Technician       0.17      0.08      0.11        13\n",
      "       Investment Analyst       0.10      0.12      0.11         8\n",
      "          Junior Designer       0.50      0.42      0.45        12\n",
      "      Mechanical Engineer       0.00      0.00      0.00        11\n",
      "    Public Policy Analyst       0.22      0.20      0.21        10\n",
      "     Researcher/Archivist       0.24      0.38      0.29        13\n",
      "        Software Engineer       0.39      0.98      0.56        57\n",
      "  Technician - Electrical       0.00      0.00      0.00        10\n",
      "  Technician - Mechanical       0.00      0.00      0.00        10\n",
      "\n",
      "                 accuracy                           0.31       240\n",
      "                macro avg       0.12      0.12      0.11       240\n",
      "             weighted avg       0.20      0.31      0.22       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"quiz/career_quiz_dataset_1200.csv\")\n",
    "\n",
    "# Combine all quiz answers into a single text feature\n",
    "feature_cols = [\n",
    "    'Q1_Favorite_Subjects', 'Q2_Enjoyed_Activities', 'Q3_Strongest_Skills',\n",
    "    'Q4_Work_Style', 'Q5_Workplace_Preference', 'Q6_Exam_Readiness',\n",
    "    'Q7_Location_Preference', 'Q8_Career_Values', 'Q9_LongTerm_Goal',\n",
    "    'Q10_Academic_Background'\n",
    "]\n",
    "\n",
    "df[\"combined_features\"] = df[feature_cols].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# Features and target\n",
    "X = df[\"combined_features\"]\n",
    "y = df[\"Recommended_Career\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Build pipeline: TF-IDF + Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, stop_words=\"english\")),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "# Train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d22913",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "965d37d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, stop_words=\"english\")),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b51f35",
   "metadata": {},
   "source": [
    "Random Forest with Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27fe340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"Recommended_Career\"])\n",
    "\n",
    "# Encode categorical text features as strings\n",
    "X = df[feature_cols].astype(str)\n",
    "\n",
    "# Simple bag-of-words encoding per column (concat all text)\n",
    "X_combined = X.agg(\" \".join, axis=1)\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "X_vec = vectorizer.fit_transform(X_combined)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_vec, y)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_vec)\n",
    "print(\"Train accuracy:\", accuracy_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39503e82",
   "metadata": {},
   "source": [
    "BERT (Best Long-Term Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "768d9f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vansh\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load data\n",
    "df[\"combined_features\"] = df[feature_cols].astype(str).agg(\" \".join, axis=1)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"combined_features\"], df[\"Recommended_Career\"], test_size=0.2, stratify=df[\"Recommended_Career\"]\n",
    ")\n",
    "\n",
    "# Hugging Face dataset\n",
    "dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "\n",
    "# Tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# (need to encode labels to integers here before training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1923ebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\vansh\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.4-cp310-cp310-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vansh\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vansh\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vansh\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.15-cp310-cp310-win_amd64.whl (452 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.4-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.6/26.2 MB 12.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.2/26.2 MB 10.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.0/26.2 MB 9.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.1/26.2 MB 9.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.2/26.2 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.1/26.2 MB 9.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.4/26.2 MB 9.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.3/26.2 MB 9.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.1/26.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.1/26.2 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.2/26.2 MB 8.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.8/26.2 MB 8.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.3/26.2 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.2 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "  Attempting uninstall: fsspec\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "    Found existing installation: fsspec 2025.9.0\n",
      "   -- -------------------------------------  1/15 [pyarrow]\n",
      "   ---------- -----------------------------  4/15 [fsspec]\n",
      "    Uninstalling fsspec-2025.9.0:\n",
      "   ---------- -----------------------------  4/15 [fsspec]\n",
      "      Successfully uninstalled fsspec-2025.9.0\n",
      "   ---------- -----------------------------  4/15 [fsspec]\n",
      "   ---------- -----------------------------  4/15 [fsspec]\n",
      "   ---------- -----------------------------  4/15 [fsspec]\n",
      "   ---------- -----------------------------  4/15 [fsspec]\n",
      "   ---------- -----------------------------  4/15 [fsspec]\n",
      "   ---------------- -----------------------  6/15 [dill]\n",
      "   ---------------- -----------------------  6/15 [dill]\n",
      "   ---------------- -----------------------  6/15 [dill]\n",
      "   ---------------- -----------------------  6/15 [dill]\n",
      "   ------------------ ---------------------  7/15 [attrs]\n",
      "   -------------------------- ------------- 10/15 [yarl]\n",
      "   ----------------------------- ---------- 11/15 [multiprocess]\n",
      "   ----------------------------- ---------- 11/15 [multiprocess]\n",
      "   ----------------------------- ---------- 11/15 [multiprocess]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ------------------------------------- -- 14/15 [datasets]\n",
      "   ---------------------------------------- 15/15 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.3.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 multidict-6.6.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-21.0.0 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script datasets-cli.exe is installed in 'c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f594bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
