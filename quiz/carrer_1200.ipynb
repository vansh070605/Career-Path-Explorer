{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5423529f",
   "metadata": {},
   "source": [
    "# Step 1: Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in your notebook after training finishes\n",
    "import os, joblib\n",
    "# create folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# 1) save sentence-transformer (preferred method)\n",
    "model_emb.save(\"models/emb_model\")   # SentenceTransformer.save\n",
    "\n",
    "# 2) save TF-IDF vectorizer, classifier and label encoder\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.joblib\")\n",
    "joblib.dump(voting_clf, \"models/voting_clf.joblib\")\n",
    "joblib.dump(le, \"models/label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0a9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cdad27",
   "metadata": {},
   "source": [
    "# Step 2: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfe2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quiz/career_quiz_dataset_1200.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c500210",
   "metadata": {},
   "source": [
    "# Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fcee619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StudentID     Q1_Favorite_Subjects         Q2_Enjoyed_Activities  \\\n",
      "0    S00001   Economics, Accountancy             Debating, Reading   \n",
      "1    S00002  Computer Science, Maths         Experiments, Research   \n",
      "2    S00003  Maths, Computer Science       Public Speaking, Coding   \n",
      "3    S00004       Chemistry, Physics               Drawing, Sports   \n",
      "4    S00005       Physics, Chemistry  Experiments, Solving Puzzles   \n",
      "\n",
      "             Q3_Strongest_Skills Q4_Work_Style Q5_Workplace_Preference  \\\n",
      "0      Communication, Creativity          Both                 Startup   \n",
      "1       Design Thinking, Writing     Practical            Research Lab   \n",
      "2  Problem Solving, Presentation   Theoretical                 Startup   \n",
      "3            Leadership, Writing     Practical                Outdoors   \n",
      "4             Research, Teamwork   Theoretical                Outdoors   \n",
      "\n",
      "  Q6_Exam_Readiness Q7_Location_Preference      Q8_Career_Values  \\\n",
      "0             Maybe                 Abroad          Job Security   \n",
      "1             Maybe                 Abroad  Creativity & Freedom   \n",
      "2                No                  India              Balanced   \n",
      "3               Yes                 Abroad  Creativity & Freedom   \n",
      "4             Maybe                 Abroad          Job Security   \n",
      "\n",
      "  Q9_LongTerm_Goal Q10_Academic_Background Recommended_Course  \\\n",
      "0           Doctor             Science-64%              B.Com   \n",
      "1          Teacher             Science-98%  B.Tech Mechanical   \n",
      "2          Teacher                Arts-79%         B.Tech CSE   \n",
      "3    Civil Servant            Commerce-68%         B.Tech ECE   \n",
      "4           Artist                Arts-91%  B.Tech Mechanical   \n",
      "\n",
      "          Recommended_Career Recommended_College_Type  Recommendation_Score  \n",
      "0                 Accountant                   Tier-2                  0.79  \n",
      "1        Mechanical Engineer                   Tier-2                  0.95  \n",
      "2          Software Engineer                   Tier-2                  0.91  \n",
      "3  Embedded Systems Engineer                   Tier-2                  0.78  \n",
      "4        Mechanical Engineer                   Tier-2                  0.94  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3b656",
   "metadata": {},
   "source": [
    "# Step 3: Split features/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f262e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['StudentID', 'Q1_Favorite_Subjects', 'Q2_Enjoyed_Activities',\n",
      "       'Q3_Strongest_Skills', 'Q4_Work_Style', 'Q5_Workplace_Preference',\n",
      "       'Q6_Exam_Readiness', 'Q7_Location_Preference', 'Q8_Career_Values',\n",
      "       'Q9_LongTerm_Goal', 'Q10_Academic_Background', 'Recommended_Course',\n",
      "       'Recommended_Career', 'Recommended_College_Type',\n",
      "       'Recommendation_Score'],\n",
      "      dtype='object')\n",
      "  StudentID     Q1_Favorite_Subjects         Q2_Enjoyed_Activities  \\\n",
      "0    S00001   Economics, Accountancy             Debating, Reading   \n",
      "1    S00002  Computer Science, Maths         Experiments, Research   \n",
      "2    S00003  Maths, Computer Science       Public Speaking, Coding   \n",
      "3    S00004       Chemistry, Physics               Drawing, Sports   \n",
      "4    S00005       Physics, Chemistry  Experiments, Solving Puzzles   \n",
      "\n",
      "             Q3_Strongest_Skills Q4_Work_Style Q5_Workplace_Preference  \\\n",
      "0      Communication, Creativity          Both                 Startup   \n",
      "1       Design Thinking, Writing     Practical            Research Lab   \n",
      "2  Problem Solving, Presentation   Theoretical                 Startup   \n",
      "3            Leadership, Writing     Practical                Outdoors   \n",
      "4             Research, Teamwork   Theoretical                Outdoors   \n",
      "\n",
      "  Q6_Exam_Readiness Q7_Location_Preference      Q8_Career_Values  \\\n",
      "0             Maybe                 Abroad          Job Security   \n",
      "1             Maybe                 Abroad  Creativity & Freedom   \n",
      "2                No                  India              Balanced   \n",
      "3               Yes                 Abroad  Creativity & Freedom   \n",
      "4             Maybe                 Abroad          Job Security   \n",
      "\n",
      "  Q9_LongTerm_Goal Q10_Academic_Background Recommended_Course  \\\n",
      "0           Doctor             Science-64%              B.Com   \n",
      "1          Teacher             Science-98%  B.Tech Mechanical   \n",
      "2          Teacher                Arts-79%         B.Tech CSE   \n",
      "3    Civil Servant            Commerce-68%         B.Tech ECE   \n",
      "4           Artist                Arts-91%  B.Tech Mechanical   \n",
      "\n",
      "          Recommended_Career Recommended_College_Type  Recommendation_Score  \n",
      "0                 Accountant                   Tier-2                  0.79  \n",
      "1        Mechanical Engineer                   Tier-2                  0.95  \n",
      "2          Software Engineer                   Tier-2                  0.91  \n",
      "3  Embedded Systems Engineer                   Tier-2                  0.78  \n",
      "4        Mechanical Engineer                   Tier-2                  0.94  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"quiz/career_quiz_dataset_1200.csv\")\n",
    "\n",
    "print(df.columns)   # show all column names\n",
    "print(df.head())    # preview first rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3e1b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3125\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "               Accountant       0.25      0.12      0.17         8\n",
      "          Artist/Designer       0.09      0.07      0.08        14\n",
      "          Ayurveda Doctor       0.00      0.00      0.00         1\n",
      "         Business Analyst       0.00      0.00      0.00         6\n",
      "           Civil Engineer       0.00      0.00      0.00        12\n",
      "             Counselor/HR       0.25      0.09      0.13        11\n",
      "                  Dentist       0.00      0.00      0.00         1\n",
      "                   Doctor       0.00      0.00      0.00         1\n",
      "        Economist/Analyst       0.25      0.10      0.14        10\n",
      "Embedded Systems Engineer       0.14      0.07      0.10        14\n",
      "        Financial Analyst       0.00      0.00      0.00         6\n",
      "        Homeopathy Doctor       0.00      0.00      0.00         1\n",
      "              IT Engineer       0.00      0.00      0.00        11\n",
      "    IT Support/Technician       0.17      0.08      0.11        13\n",
      "       Investment Analyst       0.10      0.12      0.11         8\n",
      "          Junior Designer       0.50      0.42      0.45        12\n",
      "      Mechanical Engineer       0.00      0.00      0.00        11\n",
      "    Public Policy Analyst       0.22      0.20      0.21        10\n",
      "     Researcher/Archivist       0.24      0.38      0.29        13\n",
      "        Software Engineer       0.39      0.98      0.56        57\n",
      "  Technician - Electrical       0.00      0.00      0.00        10\n",
      "  Technician - Mechanical       0.00      0.00      0.00        10\n",
      "\n",
      "                 accuracy                           0.31       240\n",
      "                macro avg       0.12      0.12      0.11       240\n",
      "             weighted avg       0.20      0.31      0.22       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"quiz/career_quiz_dataset_1200.csv\")\n",
    "\n",
    "# Combine all quiz answers into a single text feature\n",
    "feature_cols = [\n",
    "    'Q1_Favorite_Subjects', 'Q2_Enjoyed_Activities', 'Q3_Strongest_Skills',\n",
    "    'Q4_Work_Style', 'Q5_Workplace_Preference', 'Q6_Exam_Readiness',\n",
    "    'Q7_Location_Preference', 'Q8_Career_Values', 'Q9_LongTerm_Goal',\n",
    "    'Q10_Academic_Background'\n",
    "]\n",
    "\n",
    "df[\"combined_features\"] = df[feature_cols].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# Features and target\n",
    "X = df[\"combined_features\"]\n",
    "y = df[\"Recommended_Career\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Build pipeline: TF-IDF + Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, stop_words=\"english\")),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "# Train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d22913",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965d37d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, stop_words=\"english\")),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b51f35",
   "metadata": {},
   "source": [
    "Random Forest with Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fe340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"Recommended_Career\"])\n",
    "\n",
    "# Encode categorical text features as strings\n",
    "X = df[feature_cols].astype(str)\n",
    "\n",
    "# Simple bag-of-words encoding per column (concat all text)\n",
    "X_combined = X.agg(\" \".join, axis=1)\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "X_vec = vectorizer.fit_transform(X_combined)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_vec, y)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_vec)\n",
    "print(\"Train accuracy:\", accuracy_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39503e82",
   "metadata": {},
   "source": [
    "BERT (Best Long-Term Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768d9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load data\n",
    "df[\"combined_features\"] = df[feature_cols].astype(str).agg(\" \".join, axis=1)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"combined_features\"], df[\"Recommended_Career\"], test_size=0.2, stratify=df[\"Recommended_Career\"]\n",
    ")\n",
    "\n",
    "# Hugging Face dataset\n",
    "dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "\n",
    "# Tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# (need to encode labels to integers here before training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1923ebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\vansh\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vansh\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vansh\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vansh\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f594bb1",
   "metadata": {},
   "source": [
    "Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8de4af3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.3541666666666667\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "               Accountant       0.60      0.38      0.46         8\n",
      "          Artist/Designer       0.25      0.21      0.23        14\n",
      "          Ayurveda Doctor       0.00      0.00      0.00         1\n",
      "         Business Analyst       0.25      0.17      0.20         6\n",
      "           Civil Engineer       0.33      0.17      0.22        12\n",
      "             Counselor/HR       0.67      0.36      0.47        11\n",
      "                  Dentist       0.00      0.00      0.00         1\n",
      "                   Doctor       0.00      0.00      0.00         1\n",
      "        Economist/Analyst       0.20      0.10      0.13        10\n",
      "Embedded Systems Engineer       0.18      0.29      0.22        14\n",
      "        Financial Analyst       0.33      0.17      0.22         6\n",
      "        Homeopathy Doctor       0.00      0.00      0.00         1\n",
      "              IT Engineer       0.00      0.00      0.00        11\n",
      "    IT Support/Technician       0.38      0.23      0.29        13\n",
      "       Investment Analyst       0.22      0.25      0.24         8\n",
      "          Junior Designer       0.50      0.08      0.14        12\n",
      "      Mechanical Engineer       0.20      0.09      0.12        11\n",
      "    Public Policy Analyst       0.10      0.10      0.10        10\n",
      "     Researcher/Archivist       0.25      0.38      0.30        13\n",
      "        Software Engineer       0.45      0.93      0.60        57\n",
      "  Technician - Electrical       0.00      0.00      0.00        10\n",
      "  Technician - Mechanical       0.00      0.00      0.00        10\n",
      "\n",
      "                 accuracy                           0.35       240\n",
      "                macro avg       0.22      0.18      0.18       240\n",
      "             weighted avg       0.30      0.35      0.29       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f26f91",
   "metadata": {},
   "source": [
    "2. Cross-Validation (More Reliable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b002776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.30833333333333335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X_vec, y, cv=5)\n",
    "print(\"Cross-validation accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c394cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c24fc65",
   "metadata": {},
   "source": [
    "STEP 1: Load your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1316f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['StudentID', 'Q1_Favorite_Subjects', 'Q2_Enjoyed_Activities', 'Q3_Strongest_Skills', 'Q4_Work_Style', 'Q5_Workplace_Preference', 'Q6_Exam_Readiness', 'Q7_Location_Preference', 'Q8_Career_Values', 'Q9_LongTerm_Goal', 'Q10_Academic_Background', 'Recommended_Course', 'Recommended_Career', 'Recommended_College_Type', 'Recommendation_Score']\n",
      "Number of samples: 1200\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"career_quiz_dataset_1200.csv\")\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Number of samples:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc2a1ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique career clusters: ['Account/Finance' 'Engineer' 'Doctor' 'Analyst' 'Technician' 'Designer'\n",
      " 'Counseling' 'Research']\n"
     ]
    }
   ],
   "source": [
    "career_clusters = {\n",
    "    \"Doctor\": [\"Doctor\", \"Dentist\", \"Ayurveda Doctor\", \"Homeopathy Doctor\"],\n",
    "    \"Engineer\": [\"Software Engineer\", \"Civil Engineer\", \"Mechanical Engineer\",\n",
    "                 \"IT Engineer\", \"Embedded Systems Engineer\"],\n",
    "    \"Technician\": [\"Technician - Electrical\", \"Technician - Mechanical\", \"IT Support/Technician\"],\n",
    "    \"Analyst\": [\"Business Analyst\", \"Economist/Analyst\", \"Investment Analyst\", \n",
    "                \"Financial Analyst\", \"Public Policy Analyst\"],\n",
    "    \"Designer\": [\"Artist/Designer\", \"Junior Designer\"],\n",
    "    \"Research\": [\"Researcher/Archivist\"],\n",
    "    \"Account/Finance\": [\"Accountant\"],\n",
    "    \"Counseling\": [\"Counselor/HR\"],\n",
    "}\n",
    "\n",
    "# Reverse mapping: career → cluster\n",
    "career_to_cluster = {}\n",
    "for cluster, careers in career_clusters.items():\n",
    "    for c in careers:\n",
    "        career_to_cluster[c] = cluster\n",
    "\n",
    "# Map to clusters\n",
    "df[\"CareerCluster\"] = df[\"Recommended_Career\"].map(career_to_cluster)\n",
    "\n",
    "# Drop rows with unmapped careers\n",
    "df = df.dropna(subset=[\"CareerCluster\"])\n",
    "\n",
    "print(\"Unique career clusters:\", df[\"CareerCluster\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6890929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 3: Encode target labels\n",
    "# ==============================\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"CareerCluster\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71989373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataframe columns: ['StudentID', 'Q1_Favorite_Subjects', 'Q2_Enjoyed_Activities', 'Q3_Strongest_Skills', 'Q4_Work_Style', 'Q5_Workplace_Preference', 'Q6_Exam_Readiness', 'Q7_Location_Preference', 'Q8_Career_Values', 'Q9_LongTerm_Goal', 'Q10_Academic_Background', 'Recommended_Course', 'Recommended_Career', 'Recommended_College_Type', 'Recommendation_Score', 'CareerCluster']\n"
     ]
    }
   ],
   "source": [
    "print(\"Final dataframe columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a1e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['StudentID', 'Q1_Favorite_Subjects', 'Q2_Enjoyed_Activities',\n",
      "       'Q3_Strongest_Skills', 'Q4_Work_Style', 'Q5_Workplace_Preference',\n",
      "       'Q6_Exam_Readiness', 'Q7_Location_Preference', 'Q8_Career_Values',\n",
      "       'Q9_LongTerm_Goal', 'Q10_Academic_Background', 'Recommended_Course',\n",
      "       'Recommended_Career', 'Recommended_College_Type',\n",
      "       'Recommendation_Score', 'CareerCluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2fbc41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:03<00:00, 10.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 4: Create text features\n",
    "# ==============================\n",
    "\n",
    "feature_cols = [\n",
    "    \"Q1_Favorite_Subjects\",\n",
    "    \"Q2_Enjoyed_Activities\",\n",
    "    \"Q3_Strongest_Skills\",\n",
    "    \"Q4_Work_Style\",\n",
    "    \"Q5_Workplace_Preference\",\n",
    "    \"Q6_Exam_Readiness\",\n",
    "    \"Q7_Location_Preference\",\n",
    "    \"Q8_Career_Values\",\n",
    "    \"Q9_LongTerm_Goal\",\n",
    "    \"Q10_Academic_Background\"\n",
    "]\n",
    "\n",
    "# Combine all text columns into one string per student\n",
    "df_features = df[feature_cols].astype(str)\n",
    "X_text = df_features.agg(\" \".join, axis=1)\n",
    "\n",
    "# Generate embeddings using sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_emb = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "X_vec = model_emb.encode(X_text.tolist(), show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd15fb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.5\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Account/Finance       0.00      0.00      0.00         8\n",
      "        Analyst       0.44      0.34      0.38        41\n",
      "     Counseling       0.00      0.00      0.00        11\n",
      "       Designer       0.00      0.00      0.00        26\n",
      "         Doctor       0.00      0.00      0.00         3\n",
      "       Engineer       0.51      1.00      0.68       105\n",
      "       Research       0.00      0.00      0.00        13\n",
      "     Technician       1.00      0.03      0.06        33\n",
      "\n",
      "       accuracy                           0.50       240\n",
      "      macro avg       0.24      0.17      0.14       240\n",
      "   weighted avg       0.44      0.50      0.37       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 4: Create text features\n",
    "# ==============================\n",
    "feature_cols = [\n",
    "    \"Q1_Favorite_Subjects\",\n",
    "    \"Q2_Enjoyed_Activities\",\n",
    "    \"Q3_Strongest_Skills\",\n",
    "    \"Q4_Work_Style\",\n",
    "    \"Q5_Workplace_Preference\",\n",
    "    \"Q6_Exam_Readiness\",\n",
    "    \"Q7_Location_Preference\",\n",
    "    \"Q8_Career_Values\",\n",
    "    \"Q9_LongTerm_Goal\",\n",
    "    \"Q10_Academic_Background\"\n",
    "]\n",
    "\n",
    "# Combine all text columns into a single string per student\n",
    "df_features = df[feature_cols].astype(str)\n",
    "X_text = df_features.agg(\" \".join, axis=1)\n",
    "\n",
    "# Generate embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_emb = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "X_vec = model_emb.encode(X_text.tolist(), show_progress_bar=True)\n",
    "\n",
    "# ==============================\n",
    "# STEP 5: Train-Test Split\n",
    "# ==============================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"CareerCluster\"].values  # target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# STEP 6: Train RandomForest\n",
    "# ==============================\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    class_weight=\"balanced\",  # handle imbalanced clusters\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ==============================\n",
    "# STEP 7: Evaluate\n",
    "# ==============================\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cedb1d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 35/35 [00:02<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7207207207207207\n",
      "\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "  Business & Finance       0.62      0.63      0.63        41\n",
      "   Design & Creative       0.09      0.04      0.05        26\n",
      "         Engineering       0.83      0.94      0.88       138\n",
      "          Healthcare       0.00      0.00      0.00         3\n",
      "Research & Academics       0.25      0.21      0.23        14\n",
      "\n",
      "            accuracy                           0.72       222\n",
      "           macro avg       0.36      0.37      0.36       222\n",
      "        weighted avg       0.66      0.72      0.68       222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 1: Imports\n",
    "# ==============================\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ==============================\n",
    "# STEP 2: Load dataset\n",
    "# ==============================\n",
    "df = pd.read_csv(\"quiz/career_quiz_dataset_1200.csv\")  # replace with your CSV path\n",
    "\n",
    "# ==============================\n",
    "# STEP 3: Define career clusters\n",
    "# ==============================\n",
    "career_clusters = {\n",
    "    'Engineering': ['Engineer', 'Technician', 'Embedded Systems Engineer', 'IT Engineer', 'IT Support/Technician', 'Mechanical Engineer', 'Civil Engineer'],\n",
    "    'Business & Finance': ['Account/Finance', 'Analyst', 'Financial Analyst', 'Investment Analyst', 'Business Analyst'],\n",
    "    'Design & Creative': ['Designer', 'Artist/Designer', 'UX Designer', 'Graphic Designer', 'Junior Designer'],\n",
    "    'Healthcare': ['Doctor', 'Counseling', 'Ayurveda Doctor', 'Homeopathy Doctor', 'Dentist'],\n",
    "    'Research & Academics': ['Researcher', 'Public Policy Analyst', 'Economist/Analyst', 'Researcher/Archivist']\n",
    "}\n",
    "\n",
    "# Map individual career to cluster\n",
    "def map_to_cluster(career):\n",
    "    for cluster, careers in career_clusters.items():\n",
    "        for c in careers:\n",
    "            if c.lower() in str(career).lower():\n",
    "                return cluster\n",
    "    return None\n",
    "\n",
    "df['CareerCluster'] = df['Recommended_Career'].apply(map_to_cluster)\n",
    "df = df.dropna(subset=['CareerCluster'])  # drop rows with unmapped careers\n",
    "\n",
    "# ==============================\n",
    "# STEP 4: Text features\n",
    "# ==============================\n",
    "feature_cols = [\n",
    "    \"Q1_Favorite_Subjects\",\n",
    "    \"Q2_Enjoyed_Activities\",\n",
    "    \"Q3_Strongest_Skills\",\n",
    "    \"Q4_Work_Style\",\n",
    "    \"Q5_Workplace_Preference\",\n",
    "    \"Q6_Exam_Readiness\",\n",
    "    \"Q7_Location_Preference\",\n",
    "    \"Q8_Career_Values\",\n",
    "    \"Q9_LongTerm_Goal\",\n",
    "    \"Q10_Academic_Background\"\n",
    "]\n",
    "\n",
    "df_text = df[feature_cols].astype(str)\n",
    "X_text = df_text.agg(\" \".join, axis=1)\n",
    "\n",
    "# Sentence embeddings\n",
    "model_emb = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "X_vec = model_emb.encode(X_text.tolist(), show_progress_bar=True)\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['CareerCluster'])\n",
    "\n",
    "# ==============================\n",
    "# STEP 5: Train-Test Split & SMOTE\n",
    "# ==============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ==============================\n",
    "# STEP 6: Train Ensemble Model\n",
    "# ==============================\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    objective='multi:softmax',\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('rf', rf_clf), ('lr', lr_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# ==============================\n",
    "# STEP 7: Evaluation\n",
    "# ==============================\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fc7cf45",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'quiz/career_quiz_dataset_1200.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# STEP 2: Load dataset\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquiz/career_quiz_dataset_1200.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# replace with your CSV path\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# STEP 3: Define career clusters\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[0;32m     24\u001b[0m career_clusters \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEngineering\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEngineer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTechnician\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbedded Systems Engineer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIT Engineer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIT Support/Technician\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMechanical Engineer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCivil Engineer\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBusiness & Finance\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccount/Finance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalyst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinancial Analyst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvestment Analyst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBusiness Analyst\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResearch & Academics\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResearcher\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPublic Policy Analyst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEconomist/Analyst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResearcher/Archivist\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     30\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\vansh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'quiz/career_quiz_dataset_1200.csv'"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 1: Imports\n",
    "# ==============================\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# STEP 2: Load dataset\n",
    "# ==============================\n",
    "df = pd.read_csv(\"quiz/career_quiz_dataset_1200.csv\")  # replace with your CSV path\n",
    "\n",
    "# ==============================\n",
    "# STEP 3: Define career clusters\n",
    "# ==============================\n",
    "career_clusters = {\n",
    "    'Engineering': ['Engineer', 'Technician', 'Embedded Systems Engineer', 'IT Engineer', 'IT Support/Technician', 'Mechanical Engineer', 'Civil Engineer'],\n",
    "    'Business & Finance': ['Account/Finance', 'Analyst', 'Financial Analyst', 'Investment Analyst', 'Business Analyst'],\n",
    "    'Design & Creative': ['Designer', 'Artist/Designer', 'UX Designer', 'Graphic Designer', 'Junior Designer'],\n",
    "    'Healthcare': ['Doctor', 'Counseling', 'Ayurveda Doctor', 'Homeopathy Doctor', 'Dentist'],\n",
    "    'Research & Academics': ['Researcher', 'Public Policy Analyst', 'Economist/Analyst', 'Researcher/Archivist']\n",
    "}\n",
    "\n",
    "def map_to_cluster(career):\n",
    "    for cluster, careers in career_clusters.items():\n",
    "        for c in careers:\n",
    "            if c.lower() in str(career).lower():\n",
    "                return cluster\n",
    "    return None\n",
    "\n",
    "df['CareerCluster'] = df['Recommended_Career'].apply(map_to_cluster)\n",
    "df = df.dropna(subset=['CareerCluster'])\n",
    "\n",
    "# ==============================\n",
    "# STEP 4: Combine text columns\n",
    "# ==============================\n",
    "feature_cols = [\n",
    "    \"Q1_Favorite_Subjects\",\n",
    "    \"Q2_Enjoyed_Activities\",\n",
    "    \"Q3_Strongest_Skills\",\n",
    "    \"Q4_Work_Style\",\n",
    "    \"Q5_Workplace_Preference\",\n",
    "    \"Q6_Exam_Readiness\",\n",
    "    \"Q7_Location_Preference\",\n",
    "    \"Q8_Career_Values\",\n",
    "    \"Q9_LongTerm_Goal\",\n",
    "    \"Q10_Academic_Background\"\n",
    "]\n",
    "\n",
    "df_text = df[feature_cols].astype(str)\n",
    "X_text = df_text.agg(\" \".join, axis=1)\n",
    "\n",
    "# ==============================\n",
    "# STEP 5: Create embeddings and TF-IDF features\n",
    "# ==============================\n",
    "# Sentence embeddings\n",
    "model_emb = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "X_embeddings = model_emb.encode(X_text.tolist(), show_progress_bar=True)\n",
    "\n",
    "# TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=3000, stop_words=\"english\")\n",
    "X_tfidf = vectorizer.fit_transform(X_text)\n",
    "\n",
    "# Combine embeddings + TF-IDF\n",
    "X_combined = np.hstack([X_embeddings, X_tfidf.toarray()])\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['CareerCluster'])\n",
    "\n",
    "# ==============================\n",
    "# STEP 6: Train-Test Split & SMOTE\n",
    "# ==============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ==============================\n",
    "# STEP 7: Train Soft Voting Ensemble\n",
    "# ==============================\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=250,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    objective='multi:softprob',  # softprob for probability outputs\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    max_depth=None,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr_clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('rf', rf_clf), ('lr', lr_clf)],\n",
    "    voting='soft'  # use probabilities to reduce bias toward large classes\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# ==============================\n",
    "# STEP 8: Evaluate Model\n",
    "# ==============================\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0100b9ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 1) save sentence-transformer (preferred method)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel_emb\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/emb_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \u001b[38;5;66;03m# SentenceTransformer.save\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 2) save TF-IDF vectorizer, classifier and label encoder\u001b[39;00m\n\u001b[0;32m     10\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(vectorizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/tfidf_vectorizer.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_emb' is not defined"
     ]
    }
   ],
   "source": [
    "# Run in your notebook after training finishes\n",
    "import os, joblib\n",
    "# create folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# 1) save sentence-transformer (preferred method)\n",
    "model_emb.save(\"models/emb_model\")   # SentenceTransformer.save\n",
    "\n",
    "# 2) save TF-IDF vectorizer, classifier and label encoder\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.joblib\")\n",
    "joblib.dump(voting_clf, \"models/voting_clf.joblib\")\n",
    "joblib.dump(le, \"models/label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a2ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement model_emb (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for model_emb\n"
     ]
    }
   ],
   "source": [
    "pip install model_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527f93d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\vansh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7628d68e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Missing objects: ['vectorizer', 'voting_clf']. Run the training cells that create them before saving.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m missing \u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_emb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoting_clf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mle\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing objects: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Run the training cells that create them before saving.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# save sentence-transformer\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model_emb\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/emb_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Missing objects: ['vectorizer', 'voting_clf']. Run the training cells that create them before saving."
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import os, joblib\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# ensure training variables exist\n",
    "missing = [name for name in (\"model_emb\",\"vectorizer\",\"voting_clf\",\"le\") if name not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing objects: {missing}. Run the training cells that create them before saving.\")\n",
    "\n",
    "# save sentence-transformer\n",
    "model_emb.save(\"models/emb_model\")\n",
    "\n",
    "# save sklearn objects; handle XGBoost estimator special-case if needed\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.joblib\")\n",
    "try:\n",
    "    joblib.dump(voting_clf, \"models/voting_clf.joblib\")\n",
    "except Exception as e:\n",
    "    print(\"joblib.dump(voting_clf) failed, saving components individually:\", e)\n",
    "    try:\n",
    "        joblib.dump(voting_clf.named_estimators_.get(\"rf\"), \"models/rf_clf.joblib\")\n",
    "        joblib.dump(voting_clf.named_estimators_.get(\"lr\"), \"models/lr_clf.joblib\")\n",
    "        xgb_est = voting_clf.named_estimators_.get(\"xgb\")\n",
    "        if xgb_est is not None:\n",
    "            xgb_est.get_booster().save_model(\"models/xgb_clf.model\")\n",
    "        joblib.dump({\"estimators\": list(voting_clf.named_estimators_.keys()), \"voting\": voting_clf.voting}, \"models/voting_meta.joblib\")\n",
    "    except Exception as e2:\n",
    "        print(\"Failed saving voting_clf components:\", e2)\n",
    "\n",
    "joblib.dump(le, \"models/label_encoder.joblib\")\n",
    "print(\"Saved model artifacts to ./models\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d71cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
